{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WebScrapper.ipynb","provenance":[{"file_id":"1U7SQ5pkqZKGMIRzJNoW7kMBZm5UqhDA8","timestamp":1615796842051}],"collapsed_sections":[],"authorship_tag":"ABX9TyN1/gwgxZpum9F4lQgRUXE5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"oEYnvg77_aRY","executionInfo":{"status":"ok","timestamp":1616238784731,"user_tz":-60,"elapsed":977,"user":{"displayName":"Carine Therond","photoUrl":"","userId":"01656088634002615900"}}},"source":["from google.colab import drive"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_YCxDAk_g5X","executionInfo":{"status":"ok","timestamp":1616238803755,"user_tz":-60,"elapsed":18245,"user":{"displayName":"Carine Therond","photoUrl":"","userId":"01656088634002615900"}},"outputId":"e9486700-f8de-40ab-ddab-886197c2be17"},"source":["drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lKY85y1fAa59","executionInfo":{"status":"ok","timestamp":1616238807749,"user_tz":-60,"elapsed":940,"user":{"displayName":"Carine Therond","photoUrl":"","userId":"01656088634002615900"}}},"source":["import pandas as pd\n","import time\n","import re\n","import requests\n","from urllib.request import urlopen\n","import bs4\n","import warnings"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Mhb2m42_kzs","executionInfo":{"status":"ok","timestamp":1616238810123,"user_tz":-60,"elapsed":1066,"user":{"displayName":"Carine Therond","photoUrl":"","userId":"01656088634002615900"}}},"source":["def ParserCsvInputBookCrossing(currentLine):\n","    L = currentLine.split('\"')\n","    \n","    return [L[i] for i in range(16) if i%2 == 1]\n","\n","    \n","#    L = currentLine.split(';')\n","#    if len(L) == 8:\n","#        return L\n","#        \n","#    else:\n","#        g = re.search('([0-9X]+);(.+);([0-9]{4,4})(.+)(;http.+.jpg)+(;http.+.jpg)+(;http.+.jpg)+', currentLine)\n","#\n","#        g_2 = g[2].split('\"')\n","#        if len(g_2) == 1:\n","#            g_2_12 = g[2].split(';')\n","#        else:\n","#            g_2_12 = [g_2[i] for i in range(len(g_2)) if not (g_2[i] == '' or g_2[i] == ';')]\n","#     \n","#        return [x.strip(';') for x in [g[1], g_2_12[0], g_2_12[1], g[3], g[4], g[5], g[6], g[7]]]\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHkZYbYMAi2U","executionInfo":{"status":"ok","timestamp":1616238813076,"user_tz":-60,"elapsed":947,"user":{"displayName":"Carine Therond","photoUrl":"","userId":"01656088634002615900"}}},"source":["def GoogleSearchFunction(isbn = None, title = None, author = None):\n","    ''' Find information on internet about the book entered in function's arguments \n","        Either isbn = ..., Or title = ..., author = ... '''\n","    \n","    #3 kinds of books identifiers\n","    ISBNdict = {\"ISBN_10\": 0, \"ISBN_13\": 0, \"OtherID\": 0}\n","    \n","    #all is reset\n","    ISBNdict[\"ISBN_10\"] = 0.0\n","    ISBNdict[\"ISBN_13\"] = 0.0   \n","    ISBNdict[\"OtherID\"] = 0.0\n","    autGoogle = []\n","    titleSearched = ''\n","    autSearched = ''\n","    pubSearched = ''\n","    pubData = ''\n","    catSearched = ''\n","    descSearched = ''\n","    langSearched = ''\n","    imageSearched = ''\n","    pageSearched = 0\n","\n","    ISBNfound = False\n","    AUTHORfound = False\n","    repGoogle = ''\n","    \n","    try:\n","        #book is searched on internet thanks to its ISBN_10 identifier\n","        if (isbn is not None):\n","            \n","            ISBNdict[\"ISBN_10\"] = isbn\n","\n","            #Request format for a search on Google Book web site\n","            #=> We have to format the ISBN so that it is written on 10 digits => {0:0>10s}\n","            requeteIsbnGoogle = \"https://www.googleapis.com/books/v1/volumes?q=isbn:{0:0>10s}\".format(ISBNdict[\"ISBN_10\"])\n","#            print('\\n\\n', requeteIsbnGoogle)\n","    \n","            try:\n","                #In case where a book reference has been found\n","                repGoogle = pd.read_json(requeteIsbnGoogle)\n","                ISBNfound = True\n","            except:\n","                #In case where a book reference has NOT been found                \n","                repGoogle = pd.read_json(requeteIsbnGoogle, typ = 'series')\n","                ISBNfound = False\n","            \n","        \n","        #book is searched on internet thanks to its title and 1st author\n","        else:\n","            if ((title != None) and (author != None)):\n","\n","                titleSearched = title.encode('ascii', 'ignore').decode('ascii')\n","                autSearched = author.encode('ascii', 'ignore').decode('ascii')\n","                #We keep only the author familly name\n","                autSearchedInternal = autSearched.lower().split()[-1]\n","                \n","                #Request format for a search on Google Book web site\n","                #=> We must take care of ' (replace('\\'', '')) and space (replace(' ','%20'))\n","                requeteTitleGoogle = \"https://www.googleapis.com/books/v1/volumes?q=title:%s\" % (titleSearched.replace('\\'', '').replace(' ','%20'))\n","#                print(requeteTitleGoogle)\n","                repGoogle = pd.read_json(requeteTitleGoogle) \n","                \n","                #The Title has been found on Google Books\n","                #We only analyse the first book's reference retrieved => repTitleGoogle['items'][0]\n","                if (repGoogle['totalItems'][0] != 1):\n","    \n","                    if ('authors' in repGoogle['items'][0]['volumeInfo']):\n","                        \n","                        #All authors proposed by Google\n","                        autGoogle = repGoogle['items'][0]['volumeInfo']['authors']\n","                        \n","                        #Among all authors proposed by Google, we search correspondance with the first provided author\n","                        j = 0\n","                        while ((j < len(autGoogle)) and (AUTHORfound == False)):\n","                            \n","                            if (autSearchedInternal in autGoogle[j].lower()):\n","                                AUTHORfound = True  \n","                                ISBNfound = True\n","                                \n","                            j += 1\n","\n","        #ISBN or title/author has been recognized on Google Books\n","        if (ISBNfound == True):\n","            titleSearched = repGoogle['items'][0]['volumeInfo']['title']\n","            \n","            if 'subtitle' in repGoogle['items'][0]['volumeInfo']:\n","                titleSearched = titleSearched + ' : ' + repGoogle['items'][0]['volumeInfo']['subtitle']\n","            #'industryIdentifiers' stands for ISBN_10, ISBN_13 or OtherID\n","            if ('industryIdentifiers' in repGoogle['items'][0]['volumeInfo']):\n","                \n","                #Among all identifiers type proposed by Google, we search \"ISBN_10\", \"ISBN_13\" or \"OtherID\"\n","                for k in range(len(repGoogle['items'][0]['volumeInfo']['industryIdentifiers'])):\n","                    \n","                    if repGoogle['items'][0]['volumeInfo']['industryIdentifiers'][k]['type'] == \"ISBN_10\":\n","                        ISBNdict[\"ISBN_10\"] = repGoogle['items'][0]['volumeInfo']['industryIdentifiers'][k]['identifier']\n","                        ISBNfound = True\n","                        \n","                    elif repGoogle['items'][0]['volumeInfo']['industryIdentifiers'][k]['type'] == \"ISBN_13\":\n","                        ISBNdict[\"ISBN_13\"] = repGoogle['items'][0]['volumeInfo']['industryIdentifiers'][k]['identifier']\n","                        ISBNfound = True\n","                        \n","                    else:\n","                        ISBNdict[\"OtherID\"] = repGoogle['items'][0]['volumeInfo']['industryIdentifiers'][k]['identifier']\n","                        ISBNfound = True\n","\n","            if ('authors' in repGoogle['items'][0]['volumeInfo']):\n","                autSearched = repGoogle['items'][0]['volumeInfo']['authors'][0]\n","                \n","            if ('publisher' in repGoogle['items'][0]['volumeInfo']):\n","                pubSearched = repGoogle['items'][0]['volumeInfo']['publisher']\n","                                    \n","            if ('publishedDate' in repGoogle['items'][0]['volumeInfo']):\n","                pubData = repGoogle['items'][0]['volumeInfo']['publishedDate']\n","                pubData = re.search(\"[0-9]{4,4}\", pubData)[0]\n","\n","            if ('categories' in repGoogle['items'][0]['volumeInfo']):\n","                catSearched = repGoogle['items'][0]['volumeInfo']['categories'][0]\n","\n","            if ('searchInfo' in repGoogle['items'][0]):\n","                descSearched = repGoogle['items'][0]['searchInfo']['textSnippet']                    \n","\n","            if ('language' in repGoogle['items'][0]['volumeInfo']):\n","                langSearched = repGoogle['items'][0]['volumeInfo']['language']\n","\n","            if ('imageLinks' in repGoogle['items'][0]['volumeInfo']):\n","                imageSearched = repGoogle['items'][0]['volumeInfo']['imageLinks']['smallThumbnail']\n","\n","            if ('pageCount' in repGoogle['items'][0]['volumeInfo']):\n","                pageSearched = repGoogle['items'][0]['volumeInfo']['pageCount']\n","\n","        return (ISBNfound, [ISBNdict[\"ISBN_10\"], ISBNdict[\"ISBN_13\"], ISBNdict[\"OtherID\"], titleSearched, autSearched, \\\n","                           pubData, pubSearched, catSearched, descSearched, langSearched, imageSearched, pageSearched, '', '', ''])\n","\n","    except:\n","        return (False, [ISBNdict[\"ISBN_10\"], ISBNdict[\"ISBN_13\"], ISBNdict[\"OtherID\"], titleSearched, autSearched, \\\n","                           pubData, pubSearched, catSearched, descSearched, langSearched, imageSearched, pageSearched, '', '', ''])\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgzdUBJjAmm8","executionInfo":{"status":"ok","timestamp":1616238817862,"user_tz":-60,"elapsed":710,"user":{"displayName":"Carine Therond","photoUrl":"","userId":"01656088634002615900"}}},"source":["def GoodReadsSearchFunction(isbn = None, title = None, author = None):\n","    ''' Find information on internet about the book entered in function's arguments \n","        Either isbn = ..., Or title = ..., author = ... '''\n","    \n","    #3 kinds of books identifiers\n","    ISBNdict = {\"ISBN_10\": 0, \"ISBN_13\": 0, \"OtherID\": 0}\n","    \n","    #all is reset\n","    ISBNdict[\"ISBN_10\"] = 0.0\n","    ISBNdict[\"ISBN_13\"] = 0.0   \n","    ISBNdict[\"OtherID\"] = 0.0\n","    autGoodReads = ''\n","    titleSearched = ''\n","    autSearched = ''\n","    pubSearched = ''\n","    pubData = ''\n","    catSearched = ''\n","    descSearched = ''\n","    awardsSearched = ''\n","    languageSearched = ''\n","    pagesSearched = 0\n","    authorGenreSearched = ''\n","    goodreadsLinksSeriesList = []\n","\n","    AUTHORfound = False\n","    ISBNfound = False\n","    \n","    try:\n","        if(isbn is not None):\n","            #https://www.goodreads.com/search?q=195153448&qid=\n","            ISBNdict[\"ISBN_10\"] = isbn\n","    \n","            urlIdBookGoodReads_start = \"https://www.goodreads.com/search?q={0:0>10s}\".format(ISBNdict[\"ISBN_10\"])\n","            urlIdBookGoodReads_end = '&qid='\n","            bookUrlForSearch = urlIdBookGoodReads_start + urlIdBookGoodReads_end\n","#            print(bookUrlForSearch)\n","            \n","            source = urlopen(bookUrlForSearch)\n","            soup = bs4.BeautifulSoup(source, 'html.parser')\n","            ISBNfound = (soup.find(\"h1\", id=\"bookTitle\") != None)\n","\n","        else:    \n","            if ((title != None) and (author != None)):\n","                urlIdBookGoodReads_start = 'https://www.goodreads.com/search?utf8=%E2%9C%93&q='\n","                urlIdBookGoodReads_end = '&search_type=books'\n","                \n","                titleSearched = title.encode('ascii', 'ignore').decode('ascii')\n","                autSearched = author.encode('ascii', 'ignore').decode('ascii')\n","                #We keep only the author familly name\n","                autSearchedInternal = autSearched.lower().split()[-1]\n","                \n","                #First we have to find the book page: we need GoodReads identifier of the book \n","                bookUrlForSearch = urlIdBookGoodReads_start + titleSearched.replace(' ', '+') + '+' + autSearchedInternal.replace(' ', '+') + urlIdBookGoodReads_end\n","#                print(bookUrlForSearch)\n","                sourceIdBookGoodReads = urlopen(bookUrlForSearch)\n","                soupIdBookGoodReads = bs4.BeautifulSoup(sourceIdBookGoodReads, 'html.parser')\n","                \n","                #Search of the reference compliant with title and author provided, among all proposed books references\n","                booksReference = soupIdBookGoodReads.find_all(\"a\", class_=\"bookTitle\")\n","                j = 0\n","                while ((j < len(booksReference)) and (AUTHORfound == False)):\n","                    autGoodReads = booksReference[j].find_next(\"a\", class_=\"authorName\").text\n","                    \n","                    if (autSearchedInternal in autGoodReads.lower()):\n","                        AUTHORfound = True\n","                    j += 1    \n","                \n","                #Now we go to the selected book's page\n","                if (AUTHORfound == True):\n","                    source = urlopen('https://www.goodreads.com' + booksReference[j-1][\"href\"]) \n","                    soup = bs4.BeautifulSoup(source, 'html.parser')\n","                    ISBNfound = True\n","\n","        #Now we are on the specific book's web page\n","        #=> Common analysis begins\n","        if ISBNfound:\n","            titleSearched = soup.find(\"h1\", id=\"bookTitle\").text\n","            titleSearched = titleSearched.replace('\\n', '').strip()\n","            \n","            #Search of ISBN (10 and / or 13), language and awards\n","            searchForISBN_Lang_Awards_Series = soup.find(\"div\", id=\"bookDataBox\").find_all(\"div\", class_=\"clearFloats\")\n","\n","            for i in range(len(searchForISBN_Lang_Awards_Series)):\n","                \n","                if searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowTitle\").text == 'ISBN':\n","                    isbnFull = searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowItem\")\n","                    \n","                    #ISBN_10 and ISBN_13 are provided\n","                    if isbnFull.find(\"span\", class_=\"greyText\"):\n","                        ISBNdict[\"ISBN_10\"] = isbnFull.text.split(isbnFull.find(\"span\", class_=\"greyText\").text)\n","                        ISBNdict[\"ISBN_10\"] = ISBNdict[\"ISBN_10\"][0].replace('\\n', '').strip()\n","                        ISBNdict[\"ISBN_13\"] = isbnFull.find(\"span\", class_=\"greyText\").text\n","                        ISBNdict[\"ISBN_13\"] = ISBNdict[\"ISBN_13\"].split('(ISBN13: ')[1].replace(\")\", '')\n","                    #Only ISBN_10 is provided\n","                    else:\n","                        ISBNdict[\"ISBN_10\"] = isbnFull.text\n","\n","                if searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowTitle\").text == 'Edition Language':\n","                    languageSearched = searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowItem\").text\n","                    #In order to be compliant with GoogleBooks names\n","                    if (languageSearched == 'English'):\n","                        languageSearched = 'en'\n","            \n","                if searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowTitle\").text == 'Literary Awards':\n","                    awardsSearched = searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowItem\").text\n","                    awardsSearched = awardsSearched.strip()\n","\n","            \n","            #Search of published date and publisher       \n","            searchForPublished = soup.find(\"div\", id=\"details\").find_all(\"div\", class_=\"row\")\n","            for i in range(len(searchForPublished)):\n","                if 'Published' in searchForPublished[i].text:\n","                    #Current published date and additional information on first publication date is also provided\n","                    if (searchForPublished[i].find(\"nobr\", class_=\"greyText\")):\n","                        infoFirstPublished = searchForPublished[i].find(\"nobr\", class_=\"greyText\")\n","                        tempPublished = searchForPublished[i].text.split(infoFirstPublished.text)\n","                        tempPublished = tempPublished[0].strip().replace('\\n', '').replace('Published', '').split('by')\n","                        pubData = tempPublished[0].strip()\n","                        pubData = re.search(\"[0-9]{4,4}\", pubData)[0]\n","                        pubSearched = tempPublished[1].strip()\n","                    #Only current published date is provided\n","                    else:\n","                        tempPublished = searchForPublished[i].text.strip().replace('\\n', '').replace('Published', '').split('by')\n","                        pubData = tempPublished[0].strip()\n","                        pubData = re.search(\"[0-9]{4,4}\", pubData)[0]\n","                        pubSearched = tempPublished[1].strip()\n","\n","            #Search of the pages number\n","            searchForPages = soup.find(\"div\", id=\"details\").find_all(\"div\", class_=\"row\")\n","            for i in range(len(searchForPages)):\n","                if 'pages' in searchForPages[i].text:\n","                    pagesSearched = searchForPublished[i].text\n","                    pagesSearched = pagesSearched.split(',')[-1].split('pages')[0].strip()\n","        \n","            #Search for the book's genre\n","            if (soup.find(\"a\", class_=\"actionLinkLite bookPageGenreLink\")):\n","                catSearched = soup.find_all(\"a\", class_=\"actionLinkLite bookPageGenreLink\")[0].text\n","            \n","            #Search for knowing if book is part of a serie\n","            #=> If yes, we keep the URL of the other mentionned books of the serie\n","            if soup.find(\"div\", class_=\"seriesList\"):\n","                if (soup.find(\"div\", class_=\"seriesList\").find_next(\"h2\").text == 'Other books in the series'):\n","                    #We go to this specific book serie web page\n","                    linkTowardSeries = soup.find(\"div\", class_=\"seriesList\").find_next(\"h2\").find_next(\"a\")[\"href\"]\n","                    r = requests.get('https://www.goodreads.com' + linkTowardSeries)\n","                    \n","                    #We keep all the other books reference of this serie\n","                    seriesList = re.findall('href=\"/book/show/[0-9]+', str(r.content))\n","                    goodreadsLinksSeriesList = [seriesList[i].replace('href=\"', 'https://www.goodreads.com') for i in range(len(seriesList)) if i%2 == 0]\n","        \n","            #search of the author genre: we need to finf the URL of author page first\n","            autSearched = soup.find(\"a\", class_=\"authorName\").text\n","            sourceAuthor = urlopen(soup.find(\"a\", class_=\"authorName\")[\"href\"])\n","            soupAuthor = bs4.BeautifulSoup(sourceAuthor, 'html.parser')\n","            \n","            #On the author web site page, we search for the author genre\n","            searchForAuthorGenre = soupAuthor.find_all(\"div\", class_=\"dataTitle\")\n","            for i in range(len(searchForAuthorGenre)):\n","                if (searchForAuthorGenre[i].text == \"Genre\"):\n","                    authorGenreSearched = searchForAuthorGenre[i].find_next(\"div\", class_=\"dataItem\").text.split(',')[0]\n","                    authorGenreSearched = authorGenreSearched.replace('\\n', '').strip()\n","    \n","        return (ISBNfound, [ISBNdict[\"ISBN_10\"], ISBNdict[\"ISBN_13\"], ISBNdict[\"OtherID\"], titleSearched, autSearched, \\\n","                pubData, pubSearched, catSearched, descSearched, languageSearched, '', pagesSearched, awardsSearched, \\\n","                authorGenreSearched, goodreadsLinksSeriesList])\n","    \n","    except:\n","        return (False, [ISBNdict[\"ISBN_10\"], ISBNdict[\"ISBN_13\"], ISBNdict[\"OtherID\"], titleSearched, autSearched, \\\n","                pubData, pubSearched, catSearched, descSearched, languageSearched, '', pagesSearched, awardsSearched, \\\n","                authorGenreSearched, goodreadsLinksSeriesList])    \n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNjC7xmzArX9","executionInfo":{"status":"ok","timestamp":1616238984614,"user_tz":-60,"elapsed":651,"user":{"displayName":"Carine Therond","photoUrl":"","userId":"01656088634002615900"}}},"source":["def GoodReadsPartialSearchFunction(isbn =  None):\n","    \n","    awardsSearched = ''\n","    authorGenreSearched = ''\n","    goodreadsLinksSeriesList = []\n","\n","    ISBNfound = False\n","    \n","    try:\n","        urlIdBookGoodReads_start = \"https://www.goodreads.com/search?q={0:0>10s}\".format(isbn)\n","        urlIdBookGoodReads_end = '&qid='\n","        bookUrlForSearch = urlIdBookGoodReads_start + urlIdBookGoodReads_end\n","#            print(bookUrlForSearch)\n","        \n","        source = urlopen(bookUrlForSearch)\n","        soup = bs4.BeautifulSoup(source, 'html.parser')\n","        ISBNfound = (soup.find(\"h1\", id=\"bookTitle\") != None)\n","\n","\n","        #Now we are on the specific book's web page\n","        if ISBNfound:\n","            searchForISBN_Lang_Awards_Series = soup.find(\"div\", id=\"bookDataBox\").find_all(\"div\", class_=\"clearFloats\")\n","            \n","            for i in range(len(searchForISBN_Lang_Awards_Series)):\n","                if searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowTitle\").text == 'Literary Awards':\n","                    awardsSearched = searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowItem\").text\n","\n","                if searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowTitle\").text == 'Edition Language':\n","                    languageSearched = searchForISBN_Lang_Awards_Series[i].find(\"div\", \"infoBoxRowItem\").text\n","                    #In order to be compliant with GoogleBooks names\n","                    if (languageSearched == 'English'):\n","                        languageSearched = 'en'\n","\n","            #Search for knowing if book is part of a serie\n","            #=> If yes, we keep the URL of the other mentionned books of the serie\n","            if soup.find(\"div\", class_=\"seriesList\"):\n","                if (soup.find(\"div\", class_=\"seriesList\").find_next(\"h2\").text == 'Other books in the series'):\n","                    #We go to this specific book serie web page\n","                    linkTowardSeries = soup.find(\"div\", class_=\"seriesList\").find_next(\"h2\").find_next(\"a\")[\"href\"]\n","                    r = requests.get('https://www.goodreads.com' + linkTowardSeries)\n","                    \n","                    #We keep all the other books reference of this serie\n","                    seriesList = re.findall('href=\"/book/show/[0-9]+', str(r.content))\n","                    goodreadsLinksSeriesList = [seriesList[i].replace('href=\"', 'https://www.goodreads.com') for i in range(len(seriesList)) if i%2 == 0]\n","        \n","            #search of the author genre: we need to finf the URL of author page first\n","            sourceAuthor = urlopen(soup.find(\"a\", class_=\"authorName\")[\"href\"])\n","            soupAuthor = bs4.BeautifulSoup(sourceAuthor, 'html.parser')\n","            \n","            #On the author web site page, we search for the author genre\n","            searchForAuthorGenre = soupAuthor.find_all(\"div\", class_=\"dataTitle\")\n","            for i in range(len(searchForAuthorGenre)):\n","                if (searchForAuthorGenre[i].text == \"Genre\"):\n","                    authorGenreSearched = searchForAuthorGenre[i].find_next(\"div\", class_=\"dataItem\").text.split(',')[0]\n","                    authorGenreSearched = authorGenreSearched.replace('\\n', '').strip()\n","    \n","    \n","        return (ISBNfound, [awardsSearched, authorGenreSearched, goodreadsLinksSeriesList])\n","    \n","    except:\n","        return (False, [awardsSearched, authorGenreSearched, goodreadsLinksSeriesList])    \n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQu6DJm1Ayv2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wETaFOq2Azq3","executionInfo":{"status":"ok","timestamp":1616238989096,"user_tz":-60,"elapsed":807,"user":{"displayName":"Carine Therond","photoUrl":"","userId":"01656088634002615900"}}},"source":["def internetSearch(f, SaveFileName, theColumns, ind_start, ind_end):\n","\n","    NotFoundBooks = 0    \n","    pdT = pd.DataFrame(columns = theColumns)\n","\n","    for i in range(0, ind_start-1): \n","        f.readline()\n","        \n","    csvLineParsed = ParserCsvInputBookCrossing(f.readline())\n","    ret, refBookGoogle = GoogleSearchFunction(isbn = csvLineParsed[0])\n","    pdT.loc[0] = refBookGoogle \n","    pdT.loc[0:1].to_csv(SaveFileName, sep = ';', index = False, mode = 'w')\n","    \n","    #it doesn't start at 0 so that the trigger index 'len(pdT) - savingRate:len(pdT)+1' of save is correct\n","    for i in range(ind_start+1, ind_end):    \n","        retGoogle = False\n","        retGoodReads = False\n","        retPartial = False\n","\n","        lili = f.readline()\n","        #print(lili)\n","        csvLineParsed = ParserCsvInputBookCrossing(lili)\n","        #print(csvLineParsed)\n","        \n","        #First we use Google Books web site: search fastest\n","        retGoogle, refBookGoogle = GoogleSearchFunction(isbn = csvLineParsed[0])\n","        \n","        if (retGoogle == False):\n","\n","            #if ISBN not found on Google Books, we try on Google Reads\n","            retGoodReads, refBookGoodReads = GoodReadsSearchFunction(isbn = csvLineParsed[0])\n","            \n","            if (retGoodReads == False):\n","                #if ISBN not found (on Google Books and on Good Reads), \n","                #we try search on GoodReads only a search with title and author \n","                retGoodReads, refBookGoodReads = GoodReadsSearchFunction(title = csvLineParsed[1], author = csvLineParsed[2].split(';')[-1])\n","                if (retGoodReads == True):\n","                    refBook = refBookGoodReads\n","                else:\n","                    NotFoundBooks += 1\n","            else:\n","                refBook = refBookGoodReads\n","                \n","        else:\n","            refBook = refBookGoogle\n","            \n","            #If ISBN found on Google Books, we complete some columns with GoodReads search\n","            retPartial, refBookPartial = GoodReadsPartialSearchFunction(isbn = csvLineParsed[0])\n","            if (retPartial == True):\n","                refBook[-3:] = refBookPartial\n","\n","        pdT.loc[0] = refBook\n","        pdT.loc[0:1].to_csv(SaveFileName, sep = ';', index = False, mode = 'a', header = False)\n","        #Google doesn't like when too much requests are performed...\n","        #time.sleep(10.0)\n","        \n","    return NotFoundBooks\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"dTqy-QoGA3D2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bKJwNkgsA3Su","executionInfo":{"status":"ok","timestamp":1616239074732,"user_tz":-60,"elapsed":72750,"user":{"displayName":"Carine Therond","photoUrl":"","userId":"01656088634002615900"}},"outputId":"3d8d74e2-fbad-416b-988b-490dbb5b92f0"},"source":["cheminBookCrossing = '/content/drive/MyDrive/ProjetML/Base_BookCrossing/Base_originale/'\n","cheminCommon = '/content/drive/MyDrive/ProjetML/Base_BookCrossing/Base_completee/'\n","\n","SaveFileName = cheminCommon + 'bothWebSites_InternetSearch_20_03_2021_30418___.csv'\n","        \n","theColumns = ['ISBN_10', 'ISBN_13', 'OtherID', 'Book-Title', 'Book-Author', \\\n","                            'Year-Of-Publication', 'Publisher', 'Category', 'Description', 'Language', \\\n","                            'Image', 'Pages', 'Awards', \"Author's genre\", 'Same serie']\n","    \n","#List of books to search on Google\n","f = open(cheminBookCrossing + 'BX-Books.csv', encoding=\"utf8\", errors=\"replace\")\n","f.readline()\n","        \n","#Internet search function\n","with warnings.catch_warnings():\n","    warnings.warn(\"Let this be your last warning\")\n","    warnings.simplefilter(\"ignore\")\n","    NotFoundBooks = internetSearch(f, SaveFileName, theColumns, 30418, 270000) \n","    #NotFoundBooks = internetSearch(f, SaveFileName, theColumns, 0, 10) \n","    \n","print(\"Not found books: %d\" % NotFoundBooks)\n","f.close()   \n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: Let this be your last warning\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Not found books: 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gHpYHNHLBqCd"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vusQpDaDAUdl"},"source":[""],"execution_count":null,"outputs":[]}]}